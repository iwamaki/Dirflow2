# LLM設計指針の案

## 1. 目的

本設計指針は、AI File Managerアプリケーションにおける大規模言語モデル（LLM）の運用を、現在の単純なフローから、より高度で柔軟なシステムへと進化させることを目的とします。ユーザーの多様な要求に対し、LLMが効率的かつ正確に応答し、安全にタスクを実行できるアーキテクチャを確立します。特に、LLMへの入力情報の最適化と、モジュール化された再利用性の高い設計を目指します。

## 2. 主要な設計原則

*   **意図駆動型アプローチ:** ユーザーの入力からその「意図」を正確に特定し、それに基づいてLLMの振る舞いやプロンプト構築を最適化します。
*   **コンテキストの最適化（必要な時に必要な情報を）:** LLMに常にすべての情報を提供するのではなく、現在のタスクや意図に真に必要とされるコンテキスト（ファイル内容、ツール定義など）のみを動的に選択し、提示します。これにより、LLMの推論効率と精度を向上させ、不必要なトークン消費を削減します。
*   **モジュール化と再利用性:** Reactのコンポーネント設計のように、各機能（意図認識、コンテキスト提供、プロンプト戦略、ツール定義など）を独立したモジュールとして設計し、再利用性とシステムの拡張性を高めます。
*   **安全性と堅牢性:** LLMが生成するコマンドは、実行前に厳格なバリデーションプロセスを経ることで、意図しない、または危険な操作を防ぎ、システムの整合性を保ちます。
*   **柔軟性と拡張性:** 複数のLLMプロバイダーに対応し、プロンプト戦略を容易に追加・変更できる設計とすることで、将来的な技術進化や要件変更に柔軟に対応します。

## 3. 主要なコンポーネントとフロー

### 3.1. コンポーネント

*   **意図認識モジュール:**
    *   ユーザーの入力メッセージを解析し、その「意図」や「タスクの種類」（例: コード修正、ファイル操作、情報検索）を特定します。
    *   特定された意図に基づき、関連するツール群を動的に選択します。
*   **コンテキストプロバイダー群:**
    *   各タスクに必要なコンテキストデータ（ファイル内容、ファイルシステム構造、会話履歴、カスタムプロンプトなど）を、要求に応じて提供する独立したモジュール群です。
    *   例: `FileContentProvider`, `FileSystemStructureProvider`, `ConversationHistoryProvider`, `CustomPromptProvider`。
*   **ツール定義管理モジュール (ToolDefinitionProvider):**
    *   各ツール（`editFile`, `moveFile`, `readFile` など）の機能説明、引数、そして「関連する意図」などのメタデータを一元的に管理します。
    *   意図認識モジュールと連携し、タスクに関連性の高いツール定義のみを提供します。
*   **プロンプト戦略モジュール:**
    *   特定された「意図」ごとに、最適なプロンプトテンプレートと、そのテンプレートを埋めるために必要なコンテキストプロバイダーの組み合わせを定義します。
    *   各ユースケースに対応する「プロンプトのレシピ」として機能します。
*   **プロンプトオーケストレーター:**
    *   意図認識モジュールから受け取った「意図」に基づき、適切な「プロンプト戦略」を選択します。
    *   その戦略が要求するコンテキストデータを各コンテキストプロバイダーから収集し、選択されたツール定義と共に、最終的なLLMへのプロンプトを構築します。
    *   必要に応じて、最適なLLMモデルを選択します。
*   **LLMプロバイダー呼び出しモジュール:**
    *   構築されたプロンプトを、選択されたLLMモデル（Claude, OpenAI, Gemini, Local LLMなど）に送信し、応答を受け取ります。
*   **応答解析・コマンド実行・バリデーションモジュール:**
    *   LLMからの応答を解析し、JSON形式の構造化データ（特にコマンド）を抽出します。
    *   抽出されたコマンドは、実行前に厳格なバリデーションプロセスを経ます。
    *   バリデーションを通過したコマンドは、アプリケーションのファイルシステム操作モジュールなどによって実行されます。

### 3.2. コンテキストフロー

1.  **ユーザー入力:** ユーザーがチャットを通じて指示を入力します。
2.  **意図認識:** 意図認識モジュールがユーザーの入力から「意図」を特定し、関連するツール群を選択します。
3.  **プロンプトオーケストレーション:**
    *   プロンプトオーケストレーターが、特定された意図に基づき、適切なプロンプト戦略を選択します。
    *   選択された戦略が要求するコンテキストデータを、各コンテキストプロバイダーから収集します。
    *   選択されたツール定義と収集されたコンテキストデータを用いて、最終的なLLMへのプロンプトを構築します。
    *   最適なLLMモデルを選択し、LLMプロバイダー呼び出しモジュールに渡します。
4.  **LLM呼び出し:** LLMプロバイダー呼び出しモジュールが、構築されたプロンプトをLLMに送信し、応答を受け取ります。
5.  **応答処理:** 応答解析・コマンド実行・バリデーションモジュールがLLMの応答を解析し、コマンドをバリデーション後、実行します。
6.  **ユーザーへのフィードバック:** 実行結果やLLMからのメッセージをユーザーにフィードバックします。

## 4. 最新トレンドとの関連

本設計指針は、以下の最新LLM開発トレンドと密接に関連しています。

*   **LLMエージェントアーキテクチャ:** LLMを単なるテキスト生成器ではなく、意図を理解し、ツールを使いこなし、自律的にタスクを実行するエージェントとして運用します。
*   **動的プロンプトエンジニアリング:** ユーザーの意図やコンテキストに応じてプロンプトをリアルタイムで調整・生成することで、LLMの応答精度と効率を最大化します。
*   **LLMオーケストレーション:** LLM単体の限界を補完するため、意図認識、コンテキスト管理、ツール利用、応答解析といった複数のモジュールを連携させ、複雑なタスクを効率的に処理します。特に、ツール利用の最適化は、ノイズ削減と推論効率向上に貢献します。

この設計指針に基づき、AI File Managerアプリケーションは、より高度でユーザーフレンドリーなAIアシスタントへと進化することを目指します。
