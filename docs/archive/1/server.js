/* =========================================
   AI File Manager - ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ Node.js Express
   
   ã€æ¦‚è¦ã€‘
   AIçµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰API
   è¤‡æ•°LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆClaude/OpenAI/Geminiï¼‰ã¨ã®é€šä¿¡ã€æ§‹é€ åŒ–å¿œç­”è§£æã€
   ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã‚’æä¾›
   
   ã€ä¸»è¦æ©Ÿèƒ½ãƒ»è¨­å®šã€‘
   - LLM_PROVIDERS: Claudeã€OpenAIã€Gemini ã® APIè¨­å®šã¨ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
   - SYSTEM_PROMPT: AIå¿œç­”ã®æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆJSONå½¢å¼å¿œç­”æŒ‡å®šï¼‰
   - callClaudeAPI/callOpenAIAPI/callGeminiAPI: å„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ã®é€šä¿¡å‡¦ç†
   - parseStructuredResponse: JSONå½¢å¼å¿œç­”ã®è§£æã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
   - validateCommand: ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã‚³ãƒãƒ³ãƒ‰ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼
   - getMockResponse: APIæ¥ç¶šå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ç”Ÿæˆ
   
   ã€script.jsé€£æºã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‘
   - GET /api/llm-providers: åˆ©ç”¨å¯èƒ½ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãƒ»ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’é€ä¿¡
   - POST /api/chat: script.js ã‹ã‚‰ã®ãƒãƒ£ãƒƒãƒˆè¦æ±‚ã‚’å—ä¿¡ã€LLM APIå‘¼ã³å‡ºã—ã€æ§‹é€ åŒ–å¿œç­”ã‚’è¿”å´
   - GET /api/health: ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ãƒ»APIæ¥ç¶šå¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã€è¨­å®šç”»é¢ã§è¡¨ç¤º
   - GET /: index.html é™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡ï¼ˆscript.js ã®ãƒ›ã‚¹ãƒˆï¼‰
   ========================================= */

const express = require('express');
const cors = require('cors');
const path = require('path');
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors());
app.use(express.json());
app.use(express.static(path.join(__dirname)));

// LLM Providers Configuration
const LLM_PROVIDERS = {
    claude: {
        name: 'Claude (Anthropic)',
        apiUrl: 'https://api.anthropic.com/v1/messages',
        models: [
            'claude-3-sonnet-20240229',
            'claude-3-haiku-20240307',
            'claude-3-opus-20240229'
        ],
        defaultModel: 'claude-3-sonnet-20240229'
    },
    openai: {
        name: 'OpenAI GPT',
        apiUrl: 'https://api.openai.com/v1/chat/completions',
        models: [
            'gpt-4',
            'gpt-4-turbo-preview',
            'gpt-3.5-turbo'
        ],
        defaultModel: 'gpt-4'
    },
    gemini: {
        name: 'Google Gemini',
        apiUrl: 'https://generativelanguage.googleapis.com/v1beta/models',
        models: [
            'gemini-1.5-pro',
            'gemini-1.5-flash',
            'gemini-1.0-pro'
        ],
        defaultModel: 'gemini-1.5-pro'
    }
};

// ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
const SYSTEM_PROMPT = `ã‚ãªãŸã¯é«˜åº¦ãªAIãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®è‡ªç„¶ãªä¼šè©±ã‚’è¡Œã„ãªãŒã‚‰ã€å¿…è¦ã«å¿œã˜ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ æ“ä½œã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚

å¿œç­”ã¯å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§è¡Œã£ã¦ãã ã•ã„ï¼š

{
  "message": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®è‡ªç„¶ãªå¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå¿…é ˆï¼‰",
  "commands": [
    {
      "action": "create_file",
      "path": "example.txt",
      "content": "ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹",
      "description": "æ“ä½œã®èª¬æ˜"
    }
  ]
}

åˆ©ç”¨å¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼š
- create_file: ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ (path, content, description?)
- delete_file: ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ (path, description?)
- read_file: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ (path, description?)
- edit_file: ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›† (path, content, description?)
- list_files: ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º (path?, description?)

ç¾åœ¨ã®çŠ¶æ…‹:
- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {{CURRENT_PATH}}
- ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {{FILE_COUNT}}
- ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§: {{FILE_LIST}}

ãƒ«ãƒ¼ãƒ«:
1. å¿…ãšmessageãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å«ã‚ã‚‹
2. ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œä¸è¦ãªå ´åˆã¯ commands: [] ã‚’ä½¿ç”¨
3. ãƒ‘ã‚¹ã¯ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã¾ãŸã¯çµ¶å¯¾ãƒ‘ã‚¹
4. å±é™ºãªæ“ä½œï¼ˆå‰Šé™¤ï¼‰ã®å ´åˆã¯ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å«ã‚ã‚‹
5. ã‚¨ãƒ©ãƒ¼ãŒäºˆæƒ³ã•ã‚Œã‚‹å ´åˆã¯äº‹å‰ã«è­¦å‘Šã™ã‚‹
6. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å¿…ãšJSONã¨ã—ã¦æœ‰åŠ¹ãªå½¢å¼ã«ã™ã‚‹

ä¾‹:
- ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {"message": "æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã­ï¼", "commands": [{"action": "create_file", "path": "sample.txt", "content": "ã‚µãƒ³ãƒ—ãƒ«å†…å®¹", "description": "sample.txt ã‚’ä½œæˆã—ã¾ã—ãŸ"}]}
- å˜ç´”ãªä¼šè©±: {"message": "ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ", "commands": []}`;

// Claude API Call
async function callClaudeAPI(message, model = 'claude-3-sonnet-20240229', context = {}) {
    const fileList = context.fileList || [];
    const systemPrompt = SYSTEM_PROMPT
        .replace('{{CURRENT_PATH}}', context.currentPath || '/workspace')
        .replace('{{FILE_COUNT}}', fileList.length)
        .replace('{{FILE_LIST}}', JSON.stringify(fileList, null, 2));

    const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'x-api-key': process.env.ANTHROPIC_API_KEY,
            'anthropic-version': '2023-06-01'
        },
        body: JSON.stringify({
            model: model,
            max_tokens: 2048,
            messages: [
                {
                    role: 'user',
                    content: `${message}\n\n[ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±]\nç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ${context.currentPath || '/workspace'}\nãƒ•ã‚¡ã‚¤ãƒ«æ•°: ${fileList.length}\nç¾åœ¨ç·¨é›†ä¸­: ${context.currentFile || 'ãªã—'}`
                }
            ],
            system: systemPrompt
        })
    });

    if (!response.ok) {
        throw new Error(`Claude API error: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    return data.content[0].text;
}

// Gemini API Call
async function callGeminiAPI(message, model = 'gemini-1.5-pro', context = {}) {
    const fileList = context.fileList || [];
    const systemPrompt = SYSTEM_PROMPT
        .replace('{{CURRENT_PATH}}', context.currentPath || '/workspace')
        .replace('{{FILE_COUNT}}', fileList.length)
        .replace('{{FILE_LIST}}', JSON.stringify(fileList, null, 2));

    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${process.env.GOOGLE_API_KEY}`, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            contents: [
                {
                    parts: [
                        {
                            text: `${systemPrompt}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼: ${message}\n\n[ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±]\nç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ${context.currentPath || '/workspace'}\nãƒ•ã‚¡ã‚¤ãƒ«æ•°: ${fileList.length}`
                        }
                    ]
                }
            ],
            generationConfig: {
                temperature: 0.7,
                topK: 40,
                topP: 0.95,
                maxOutputTokens: 2048,
                stopSequences: []
            },
            safetySettings: [
                {
                    category: "HARM_CATEGORY_HARASSMENT",
                    threshold: "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    category: "HARM_CATEGORY_HATE_SPEECH",
                    threshold: "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    threshold: "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    category: "HARM_CATEGORY_DANGEROUS_CONTENT",
                    threshold: "BLOCK_MEDIUM_AND_ABOVE"
                }
            ]
        })
    });

    if (!response.ok) {
        throw new Error(`Gemini API error: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    
    if (data.candidates && data.candidates[0] && data.candidates[0].content) {
        return data.candidates[0].content.parts[0].text;
    } else {
        throw new Error('Unexpected Gemini API response format');
    }
}

// OpenAI API Call
async function callOpenAIAPI(message, model = 'gpt-4', context = {}) {
    const fileList = context.fileList || [];
    const systemPrompt = SYSTEM_PROMPT
        .replace('{{CURRENT_PATH}}', context.currentPath || '/workspace')
        .replace('{{FILE_COUNT}}', fileList.length)
        .replace('{{FILE_LIST}}', JSON.stringify(fileList, null, 2));

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
        },
        body: JSON.stringify({
            model: model,
            max_tokens: 2048,
            messages: [
                {
                    role: 'system',
                    content: systemPrompt
                },
                {
                    role: 'user',
                    content: `${message}\n\n[ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±]\nç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ${context.currentPath || '/workspace'}\nãƒ•ã‚¡ã‚¤ãƒ«æ•°: ${fileList.length}`
                }
            ],
            temperature: 0.7
        })
    });

    if (!response.ok) {
        throw new Error(`OpenAI API error: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
}

// æ§‹é€ åŒ–å¿œç­”ãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆJSONå½¢å¼å¯¾å¿œï¼‰
function parseStructuredResponse(response) {
    try {
        // JSONå½¢å¼ã‚’å„ªå…ˆçš„ã«è©¦è¡Œ
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
            try {
                const parsed = JSON.parse(jsonMatch[0]);
                return {
                    message: parsed.message || 'AIå¿œç­”ã‚’å‡¦ç†ä¸­...',
                    commands: Array.isArray(parsed.commands) ? parsed.commands : [],
                    success: true
                };
            } catch (e) {
                console.warn('JSON parse failed:', e);
            }
        }

        // JSONãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦æ‰±ã†
        return {
            message: response,
            commands: [],
            success: false,
            warning: 'AIã®å¿œç­”ã‚’JSONå½¢å¼ã§è§£æã§ãã¾ã›ã‚“ã§ã—ãŸ'
        };

    } catch (error) {
        console.warn('Failed to parse structured response:', error);
        return {
            message: response || 'AIã‹ã‚‰ã®å¿œç­”ã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã§ã—ãŸ',
            commands: [],
            success: false,
            error: error.message
        };
    }
}

// ã‚³ãƒãƒ³ãƒ‰ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
function validateCommand(command) {
    const allowedActions = ['create_file', 'delete_file', 'read_file', 'edit_file', 'list_files'];
    
    if (!command.action || !allowedActions.includes(command.action)) {
        throw new Error(`æœªã‚µãƒãƒ¼ãƒˆã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: ${command.action}`);
    }

    // ãƒ‘ã‚¹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
    if (command.path) {
        if (typeof command.path !== 'string' || 
            command.path.includes('..') || 
            command.path.includes('~') || 
            command.path.startsWith('/etc') || 
            command.path.startsWith('/var')) {
            throw new Error(`å®‰å…¨ã§ãªã„ãƒ‘ã‚¹: ${command.path}`);
        }
    }

    // å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
    const requiredFields = {
        'create_file': ['path'],
        'delete_file': ['path'],
        'read_file': ['path'],
        'edit_file': ['path', 'content'],
        'list_files': []
    };

    const required = requiredFields[command.action];
    for (const field of required) {
        if (!command[field] && command[field] !== '') {
            throw new Error(`å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: ${field}`);
        }
    }

    return true;
}

// Fallback Mock Response
function getMockResponse(message, context = {}) {
    const cmd = message.toLowerCase();
    
    if (cmd.includes('help') || cmd.includes('ãƒ˜ãƒ«ãƒ—')) {
        return {
            message: `ğŸ¤– AI File Manager ã®ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§ï¼š
        
**ğŸ“‹ åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰:**
â€¢ **ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ** - "æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œã£ã¦" "sample.txt ã‚’ä½œæˆ"
â€¢ **ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿** - "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã‚“ã§" "å†…å®¹ã‚’è¡¨ç¤ºã—ã¦"  
â€¢ **ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†** - "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¦" "å†…å®¹ã‚’å¤‰æ›´ã—ã¦"
â€¢ **ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤** - "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦" "ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¶ˆã—ã¦"
â€¢ **ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§** - "ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§" "ä½•ãŒã‚ã‚‹ã‹æ•™ãˆã¦"

**ğŸ“± æ“ä½œæ–¹æ³•:**
â€¢ **ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º** - ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯ã§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
â€¢ **ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ** - ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é•·æŠ¼ã—ã§æ“ä½œãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤º
â€¢ **ç·¨é›†åˆ‡æ›¿** - å³ä¸Šã®âœï¸ãƒœã‚¿ãƒ³ã§ç·¨é›†/ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ‡ã‚Šæ›¿ãˆ
â€¢ **AIã‚³ãƒãƒ³ãƒ‰** - è‡ªç„¶ãªæ—¥æœ¬èªã§ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãŒå¯èƒ½

ä¾‹: "README.mdã‚’ä½œæˆã—ã¦ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®èª¬æ˜ã‚’æ›¸ã„ã¦"`,
            commands: []
        };
    }

    // ç°¡å˜ãªã‚³ãƒãƒ³ãƒ‰æ¤œå‡ºã¨ãƒ¢ãƒƒã‚¯å¿œç­”
    if (cmd.includes('ä½œæˆ') || cmd.includes('create')) {
        return {
            message: "ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ï¼ˆãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰: APIæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰",
            commands: []
        };
    }

    if (cmd.includes('ä¸€è¦§') || cmd.includes('list')) {
        return {
            message: `ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ${context.currentPath || '/workspace'}\nãƒ•ã‚¡ã‚¤ãƒ«æ•°: ${context.fileList?.length || 0}`,
            commands: []
        };
    }

    const mockResponses = [
        "ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚",
        "AIã«ã‚ˆã‚‹åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚", 
        "å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚",
        "ã”è³ªå•ã«ãŠç­”ãˆã—ã¾ã™ã€‚ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        "ç†è§£ã—ã¾ã—ãŸã€‚ä»–ã«ã‚‚ä½•ã‹ã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ã§ã—ãŸã‚‰ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚"
    ];
    
    return {
        message: mockResponses[Math.floor(Math.random() * mockResponses.length)],
        commands: []
    };
}

// API Routes

// Get available LLM providers and models
app.get('/api/llm-providers', (req, res) => {
    res.json(LLM_PROVIDERS);
});

// Chat endpoint (æ”¹è‰¯ç‰ˆ)
app.post('/api/chat', async (req, res) => {
    try {
        const { message, provider = 'claude', model, context = {} } = req.body;

        if (!message || typeof message !== 'string') {
            return res.status(400).json({ 
                error: 'Message is required and must be a string' 
            });
        }

        let response;
        const selectedModel = model || LLM_PROVIDERS[provider]?.defaultModel;

        switch (provider) {
            case 'claude':
                if (!process.env.ANTHROPIC_API_KEY) {
                    throw new Error('Anthropic API key not configured');
                }
                response = await callClaudeAPI(message, selectedModel, context);
                break;

            case 'openai':
                if (!process.env.OPENAI_API_KEY) {
                    throw new Error('OpenAI API key not configured');
                }
                response = await callOpenAIAPI(message, selectedModel, context);
                break;

            case 'gemini':
                if (!process.env.GOOGLE_API_KEY) {
                    throw new Error('Google API key not configured');
                }
                response = await callGeminiAPI(message, selectedModel, context);
                break;

            default:
                console.warn(`Unknown provider: ${provider}, using mock response`);
                const mockResult = getMockResponse(message, context);
                return res.json({
                    message: mockResult.message,
                    commands: mockResult.commands,
                    provider: 'fallback',
                    model: 'mock',
                    timestamp: new Date().toISOString(),
                    warning: 'ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”: æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒç„¡åŠ¹ã§ã™'
                });
        }

        // æ§‹é€ åŒ–å¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹
        const parsedResponse = parseStructuredResponse(response);

        // ã‚³ãƒãƒ³ãƒ‰ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        const validatedCommands = [];
        if (parsedResponse.commands && parsedResponse.commands.length > 0) {
            for (const command of parsedResponse.commands) {
                try {
                    validateCommand(command);
                    validatedCommands.push(command);
                } catch (error) {
                    console.warn(`Invalid command filtered out: ${error.message}`);
                    // ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã¯é™¤å¤–ã™ã‚‹ãŒã€ã‚¨ãƒ©ãƒ¼ã«ã¯ã—ãªã„
                }
            }
        }

        res.json({ 
            message: parsedResponse.message,
            commands: validatedCommands,
            rawResponse: response,
            provider,
            model: selectedModel,
            timestamp: new Date().toISOString(),
            parseSuccess: parsedResponse.success,
            warning: parsedResponse.warning
        });

    } catch (error) {
        console.error('Chat API error:', error);
        
        // APIå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
        const fallbackResult = getMockResponse(req.body.message, req.body.context);
        
        res.status(200).json({
            message: fallbackResult.message + "\n\nâš ï¸ (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”: APIæ¥ç¶šã‚¨ãƒ©ãƒ¼ã®ãŸã‚)",
            commands: [],
            provider: 'fallback',
            model: 'mock',
            timestamp: new Date().toISOString(),
            warning: 'APIæ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚',
            error: error.message
        });
    }
});

// Health check endpoint
app.get('/api/health', (req, res) => {
    const status = {
        status: 'healthy',
        timestamp: new Date().toISOString(),
        providers: {},
        features: {
            basic_commands: true,
            file_operations: true,
            json_parsing: true
        }
    };

    // Check if API keys are configured
    status.providers.claude = !!process.env.ANTHROPIC_API_KEY;
    status.providers.openai = !!process.env.OPENAI_API_KEY;
    status.providers.gemini = !!process.env.GOOGLE_API_KEY;

    res.json(status);
});

// Serve static files
app.get('/', (req, res) => {
    res.sendFile(path.join(__dirname, 'index.html'));
});

// Error handling middleware
app.use((err, req, res, next) => {
    console.error('Server error:', err);
    res.status(500).json({ 
        error: 'Internal server error',
        message: process.env.NODE_ENV === 'development' ? err.message : 'Something went wrong'
    });
});

// Start server
app.listen(PORT, () => {
    console.log(`ğŸš€ AI File Manager Server running on http://localhost:${PORT}`);
    console.log(`ğŸ“‹ Available providers:`);
    
    Object.entries(LLM_PROVIDERS).forEach(([key, provider]) => {
        const hasKey = key === 'claude' ? !!process.env.ANTHROPIC_API_KEY : 
                       key === 'openai' ? !!process.env.OPENAI_API_KEY :
                       key === 'gemini' ? !!process.env.GOOGLE_API_KEY : false;
        console.log(`   ${provider.name}: ${hasKey ? 'âœ…' : 'âŒ'}`);
    });
    
    console.log(`\nğŸ¯ Phase 1 æ©Ÿèƒ½æœ‰åŠ¹:`);
    console.log(`   ğŸ“ create_file - ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ`);
    console.log(`   ğŸ“– read_file - ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿`);
    console.log(`   âœï¸ edit_file - ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†`);
    console.log(`   ğŸ—‘ï¸ delete_file - ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤`);
    console.log(`   ğŸ“‹ list_files - ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§`);
    
    if (!process.env.ANTHROPIC_API_KEY && !process.env.OPENAI_API_KEY && !process.env.GOOGLE_API_KEY) {
        console.log(`\nâš ï¸  No API keys configured. Add them to .env file:`);
        console.log(`   ANTHROPIC_API_KEY=your_claude_api_key`);
        console.log(`   OPENAI_API_KEY=your_openai_api_key`);
        console.log(`   GOOGLE_API_KEY=your_gemini_api_key`);
    }
});
